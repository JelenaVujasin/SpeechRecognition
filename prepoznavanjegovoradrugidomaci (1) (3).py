# -*- coding: utf-8 -*-
"""PrepoznavanjeGovoraDrugiDomaci.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TR_SjidkRDxDJMBOgAAB65-fboE1y7Vv
"""

!pip install scikit-learn librosa==0.9.1 sounddevice matplotlib

from google.colab import drive
drive.mount('/content/drive')

"""Biblioteke audio fajlovi, referentni audio fajlovi i njihova normalizacija"""

import os
import librosa
import librosa.display
import matplotlib.pyplot as plt
import scipy.signal
import numpy as np
import soundfile as sf
from collections import defaultdict

def load_files_from_directory(directory_path):
    files = []
    for filename in os.listdir(directory_path):
        if filename.endswith(".wav"):
            filepath = os.path.join(directory_path, filename)
            files.append((filepath))
    return files

audio_files = load_files_from_directory("/content/drive/MyDrive/PrepoznavanjeGovora/Cifre")
ref_audio_files = load_files_from_directory("/content/drive/MyDrive/PrepoznavanjeGovora/RefVrednosti")
partner_audio_files = load_files_from_directory("/content/drive/MyDrive/PrepoznavanjeGovora/Partneri")

normalized_audio_files = []
for file in audio_files:
    y_norm, sr = normalize_audio(file)
    normalized_path = file.replace('.wav', '_normalized.wav')
    sf.write(normalized_path, y_norm, sr)
    normalized_audio_files.append(normalized_path)

normalized_ref_audio_files = []
for file in ref_audio_files:
    y_norm, sr = normalize_audio(file)
    # Kreiranje novog puta za snimak
    normalized_path = file.replace('.wav', '_normalized.wav')
    # Snimanje normalizovanog audio snimka
    sf.write(normalized_path, y_norm, sr)
    normalized_ref_audio_files.append(normalized_path)

normalized_partner_audio_files = []
for file in partner_audio_files:
    y_norm, sr = normalize_audio(file)
    normalized_path = file.replace('.wav', '_normalized.wav')
    sf.write(normalized_path, y_norm, sr)
    normalized_partner_audio_files.append(normalized_path)

"""DTW Algoritam"""

def dtw_distance(sequence1, sequence2):
    n, m = sequence1.shape[1], sequence2.shape[1]
    dtw_matrix = np.full((n+1, m+1), np.inf)
    dtw_matrix[0, 0] = 0

    for i in range(1, n+1):
        for j in range(1, m+1):
            cost = np.linalg.norm(sequence1[:, i-1] - sequence2[:, j-1])
            dtw_matrix[i, j] = cost + min(dtw_matrix[i-1, j],
                                          dtw_matrix[i, j-1],
                                          dtw_matrix[i-1, j-1])

    return dtw_matrix[n, m]

def dtw_distance_lpc(sequence1, sequence2):
    n, m = len(sequence1), len(sequence2)
    dtw_matrix = np.full((n+1, m+1), np.inf)
    dtw_matrix[0, 0] = 0

    for i in range(1, n+1):
        for j in range(1, m+1):
            cost = np.abs(sequence1[i-1] - sequence2[j-1])
            dtw_matrix[i, j] = cost + min(dtw_matrix[i-1, j],
                                          dtw_matrix[i, j-1],
                                          dtw_matrix[i-1, j-1])

    return dtw_matrix[n, m]

"""MFCC"""

num_files = len(audio_files)


fig, axes = plt.subplots(1, num_files, figsize=(40, 4))

for i, file in enumerate(audio_files):
    y, sr = librosa.load(file, sr=None)

    mfcc = librosa.feature.mfcc(y=y, sr=sr)

    file_number = os.path.basename(file)[0]

    librosa.display.specshow(mfcc, x_axis='time', ax=axes[i])
    axes[i].set_title(f'MFCC for file {file_number}')

plt.tight_layout()
plt.show()
def recognize_digit_mfcc(audio_file, ref_audio_files):
    y, sr = librosa.load(audio_file, sr=None)
    audio_features = librosa.feature.mfcc(y = y, sr = sr, n_mfcc = 64, n_fft=1024, hop_length=256)

    min_dtw_distance = float('inf')
    recognized_digit = None

    for ref_file in ref_audio_files:
        ref_y, ref_sr = librosa.load(ref_file, sr=None)
        ref_features = librosa.feature.mfcc(y = ref_y, sr = ref_sr, n_mfcc = 64, n_fft=1024, hop_length=256)

        dtw_dist = dtw_distance(audio_features, ref_features)
        if dtw_dist < min_dtw_distance:
            min_dtw_distance = dtw_dist
            recognized_digit = os.path.basename(ref_file)[0]

    return recognized_digit

total_score_mfcc = 0
for audio_file in normalized_audio_files:
    recognized_digit = recognize_digit_mfcc(audio_file, normalized_ref_audio_files)
    print(f"Cifra u {audio_file} je {recognized_digit}")
    if(os.path.basename(audio_file)[0]==recognized_digit):
      total_score_mfcc = total_score_mfcc+1
print("Ukupan broj pogodjenih cifara je:", total_score_mfcc)

"""Mel Spectrogram"""

num_files = len(audio_files)

fig, axes = plt.subplots(1, num_files, figsize=(40, 4))

for i, file in enumerate(audio_files):
    y, sr = librosa.load(file, sr=None)

    mel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=512)

    librosa.display.specshow(librosa.power_to_db(mel_spect, ref=np.max), y_axis='mel', fmax=8000, x_axis='time', ax=axes[i])
    axes[i].set_title(f'Mel Spectrogram for file {os.path.basename(file)[0]}')


plt.tight_layout()
plt.show()

def recognize_digit_melspec(audio_file, ref_audio_files):
    y, sr = librosa.load(audio_file, sr=None)
    audio_features = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=512)
    audio_features_db = librosa.power_to_db(audio_features, ref=np.max)

    min_dtw_distance = float('inf')
    recognized_digit = None

    # Upoređivanje sa svakim referentnim snimkom
    for ref_file in ref_audio_files:
        ref_y, ref_sr = librosa.load(ref_file, sr=None)
        ref_features = librosa.feature.melspectrogram(y=ref_y, sr=ref_sr, n_mels=128, n_fft=2048, hop_length=512)
        ref_features_db = librosa.power_to_db(ref_features, ref=np.max)

        # Izračunavanje DTW rastojanja
        dtw_dist = dtw_distance(audio_features_db, ref_features_db)
        if dtw_dist < min_dtw_distance:
            min_dtw_distance = dtw_dist
            recognized_digit = os.path.basename(ref_file)[0]

    return recognized_digit
total_score_mel_spec = 0
for audio_file in normalized_audio_files:
    recognized_digit = recognize_digit_melspec(audio_file, normalized_ref_audio_files)
    print(f"Cifra u  {audio_file} je {recognized_digit}")
    if(os.path.basename(audio_file)[0]==recognized_digit):
      total_score_mel_spec = total_score_mel_spec+1
print("Ukupan broj pogodjenih cifara je:", total_score_mel_spec)

"""LPC"""

def levinson_durbin(signal, order):
    """Implementacija Levinson-Durbin algoritma za izračunavanje LPC koeficijenata."""
    autocorr = scipy.signal.correlate(signal, signal, mode='full')
    autocorr = autocorr[len(autocorr) // 2:]

    # Inicijalizacija
    a = np.zeros(order + 1)
    e = autocorr[0]

    for i in range(1, order + 1):
        # Levinson-Durbin rekurzija
        acc = sum([a[j] * autocorr[i - j] for j in range(1, i)])
        next_coeff = - (autocorr[i] + acc) / e

        # Azuriranje koeficijenata
        a[1:i+1] = a[1:i+1] + next_coeff * a[1:i+1][::-1]
        a[i] = next_coeff

        # Azuriranje greske
        e *= 1 - next_coeff ** 2

    return a


num_files = len(audio_files)


fig, axes = plt.subplots(1, num_files, figsize=(40, 4))

for i, file in enumerate(audio_files):

    y, sr = librosa.load(file, sr=None)

    lpc_order = 10

    lpc_coeffs = levinson_durbin(y, lpc_order)

    axes[i].stem(lpc_coeffs)
    axes[i].set_title(f'LPC Coefficients for file {os.path.basename(file)[0]}')
    axes[i].set_xlabel('Coefficient Index')
    axes[i].set_ylabel('Coefficient Value')


plt.tight_layout()
plt.show()


def recognize_digit_lpc(audio_file, ref_audio_files, lpc_func, lpc_order):
    y, sr = librosa.load(audio_file, sr=None)
    audio_features = lpc_func(y, lpc_order)

    min_dtw_distance = float('inf')
    recognized_digit = None

    # Upoređivanje sa svakim referentnim snimkom
    for ref_file in ref_audio_files:
        # Učitavanje i izračunavanje LPC karakteristika za referentni snimak
        ref_y, ref_sr = librosa.load(ref_file, sr=None)
        ref_features = lpc_func(ref_y, lpc_order)

        # Izračunavanje DTW rastojanja
        dtw_dist = dtw_distance_lpc(audio_features, ref_features)
        if dtw_dist < min_dtw_distance:
            min_dtw_distance = dtw_dist
            recognized_digit = os.path.basename(ref_file)[0]

    return recognized_digit
total_score_lpc = 0
# Provera prepoznavanja cifara za sve audio snimke koristeći LPC
for audio_file in normalized_audio_files:
    recognized_digit = recognize_digit_lpc(audio_file, normalized_ref_audio_files, levinson_durbin, 10)
    print(f"Cifra u {audio_file} je {recognized_digit}")
    if(os.path.basename(audio_file)[0]==recognized_digit):
      total_score_lpc = total_score_lpc+1
print("Ukupan broj pogodjenih cifara je:", total_score_lpc)

"""Pronalazenje glasovnog partnera"""

def distance_mfcc(audio_file, ref_audio_file):
    y, sr = librosa.load(audio_file, sr=None)
    audio_features = librosa.feature.mfcc(y = y, sr = sr, n_mfcc = 64, n_fft=1024, hop_length=256)

    min_dtw_distance = float('inf')
    recognized_digit = None

    ref_y, ref_sr = librosa.load(ref_audio_file, sr=None)
    ref_features = librosa.feature.mfcc(y = y, sr = sr, n_mfcc = 64, n_fft=1024, hop_length=256)
    dtw_dist = dtw_distance(audio_features, ref_features)
    if dtw_dist < min_dtw_distance:
      min_dtw_distance = dtw_dist

    return min_dtw_distance

def distance_melspec(audio_file, ref_audio_file):
    y, sr = librosa.load(audio_file, sr=None)
    audio_features = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=512)
    audio_features_db = librosa.power_to_db(audio_features, ref=np.max)

    min_dtw_distance = float('inf')
    recognized_digit = None

    ref_y, ref_sr = librosa.load(ref_audio_file, sr=None)
    ref_features = librosa.feature.melspectrogram(y=ref_y, sr=ref_sr, n_mels=128, n_fft=2048, hop_length=512)
    ref_features_db = librosa.power_to_db(ref_features, ref=np.max)

    # Izračunavanje DTW rastojanja
    dtw_dist = dtw_distance(audio_features_db, ref_features_db)
    if dtw_dist < min_dtw_distance:
      min_dtw_distance = dtw_dist

    return min_dtw_distance

def distance_lpc(audio_file, ref_audio_file, lpc_func, lpc_order):

    y, sr = librosa.load(audio_file, sr=None)
    audio_features = lpc_func(y, lpc_order)

    min_dtw_distance = float('inf')
    recognized_digit = None

    ref_y, ref_sr = librosa.load(ref_audio_file, sr=None)
    ref_features = lpc_func(ref_y, lpc_order)

    # Izračunavanje DTW rastojanja
    dtw_dist = dtw_distance_lpc(audio_features, ref_features)
    if dtw_dist < min_dtw_distance:
        min_dtw_distance = dtw_dist

    return min_dtw_distance

def group_files_by_index(audio_files):
    grouped_files = defaultdict(list)
    for file in audio_files:
        # Parsiranje delova imena fajla
        parts = os.path.basename(file).split('-')
        if len(parts) >= 3:
            index = '-'.join(parts[1:3])  # Spajanje drugog i trećeg dela
            grouped_files[index].append(file)
    return grouped_files

def calculate_total_distance(audio_file, partner_files, distance_func):
    total_distance = 0
    for partner_file in partner_files:
        total_distance += distance_func(audio_file, partner_file)
    return total_distance

def calculate_total_distance_lpc(audio_file, partner_files, distance_func):
    total_distance = 0
    for partner_file in partner_files:
        total_distance += distance_func(audio_file, partner_file, levinson_durbin, 10)
    return total_distance

def remove_normalized_suffix(file_name):
    return file_name.replace('_normalized.wav', '')

min_mfcc_index = None
min_mel_spec_index = None
min_lpc_index = None
min_mfcc_distance = float('inf')
min_mel_spec_distance = float('inf')
min_lpc_distance = float('inf')

grouped_partner_files = group_files_by_index(normalized_partner_audio_files)

def get_first_number_from_filename(file_name):
    return file_name.split('-')[0].split('/')[-1]

for index, partner_files in grouped_partner_files.items():
    total_mfcc_distance = 0
    total_mel_spec_distance = 0
    total_lpc_distance = 0

    for audio_file in audio_files:
        audio_file_number = get_first_number_from_filename(audio_file)

        # Pronalazak odgovarajućeg partnera fajla sa istim brojem
        partner_file = next((pf for pf in partner_files if get_first_number_from_filename(pf) == audio_file_number), None)
        if partner_file is not None:
            total_mfcc_distance += distance_mfcc(audio_file, partner_file)
            total_mel_spec_distance += distance_melspec(audio_file, partner_file)
            total_lpc_distance += distance_lpc(audio_file, partner_file, levinson_durbin, 10)

    # Provera da li je ovo najmanja ukupna udaljenost
    if total_mfcc_distance < min_mfcc_distance:
        min_mfcc_distance = total_mfcc_distance
        min_mfcc_index = remove_normalized_suffix(index)
    if total_mel_spec_distance < min_mel_spec_distance:
        min_mel_spec_distance = total_mel_spec_distance
        min_mel_spec_index = remove_normalized_suffix(index)
    if total_lpc_distance < min_lpc_distance:
        min_lpc_distance = total_lpc_distance
        min_lpc_index = remove_normalized_suffix(index)


print("Po MFCC-u, moj glasovni partner je student sa indeksom:", min_mfcc_index)
print("Po Mel Spectrogram-u, moj glasovni partner je student sa indeksom:", min_mel_spec_index)
print("Po LPC-u, moj glasovni partner je student sa indeksom:", min_lpc_index)

"""Pruning strategije u Dynamic Time Warping (DTW) odabiraju se prema specifičnim zahtevima i karakteristikama podataka s ciljem postizanja ravnoteže između tačnosti i računske efikasnosti.

Dynamic Time Warping (DTW) pruning je tehnika koja se primenjuje radi efikasnijeg izračunavanja DTW udaljenosti između dve sekvence. DTW algoritam pronalazi optimalno poravnanje između vremenskih serija koje mogu varirati po brzini. Standardni DTW može biti računski zahtevan, posebno za duže sekvence, zbog izračunavanja udaljenosti za sve kombinacije tačaka između sekvenci. Pruning strategije u DTW-u usmerene su na smanjenje broja računskih operacija ograničavanjem prostora pretrage. Evo nekoliko uobičajenih pristupa DTW pruning:

Sakoe-Chiba metoda: Ovaj pristup ograničava DTW na traku oko dijagonale matrice udaljenosti. Parametar širine trake određuje koliko daleko od dijagonale DTW može istraživati. Efikasnost ovog pristupa dolazi do izražaja kada su sekvence slične, pa je njihovo optimalno poravnanje vjerojatno blizu dijagonale.

Itakura paralelogram: Slično kao Sakoe-Chiba metoda, Itakura paralelogram ograničava prostor pretrage, ali u obliku paralelograma. Ovaj pristup je koristan kada su sekvence sličnog oblika, ali se razlikuju u dužini ili su linearno deformirane.

R prozor: Ovaj pristup koristi pravokutnik unutar matrice udaljenosti i ograničava pretragu na to područje. Ova metoda je korisna kada postoji prethodno znanje o tome koliko sekvence mogu biti rastegnute ili stisnute u odnosu jedna na drugu.

Koraci (ograničenja koraka): DTW može koristiti različite obrasce koraka koji definiraju dopuštene pomeraje po matrici udaljenosti. Ograničavanjem dopuštenih koraka postiže se ravnoteža između računske učinkovitosti i kvaliteta poravnanja.

Rano napuštanje (Early abandoning): Ako je cilj pronaći najmanju DTW udaljenost između sekvence i skupa sekvenci, računanje se može prekinuti čim trenutna udaljenost premaši već pronađenu minimalnu udaljenost. Ovo značajno smanjuje broj potrebnih računskih operacija.

Donje granice (Lower bounding): Ova strategija koristi se za brzo odbacivanje nekih sekvenci koje sigurno neće biti najbliže traženoj sekvenci. To se postiže izračunavanjem minimalnih udaljenosti koje su brže za izračunavanje od potpune DTW metode, ali koje su korisne za eliminaciju određenih kandidata.
"""